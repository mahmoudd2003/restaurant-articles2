# app.py
# -*- coding: utf-8 -*-

import os
import io
import csv
import json
import math
import unicodedata
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

import streamlit as st

# --- Ù…Ø¬Ù„Ø¯Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© ---
os.makedirs("data", exist_ok=True)
os.makedirs("logs", exist_ok=True)

# --- Ø§Ù„Ù„ÙˆØ¬ÙŠÙ†Øº (ÙŠØªØ·Ù„Ø¨ utils/logging_setup.py ÙƒÙ…Ø§ Ø£Ø±Ø³Ù„Øª Ù„Ùƒ) ---
from utils.logging_setup import (
    init_logging,
    get_logger,
    set_correlation_id,
    with_context,
    log_exception,
)
init_logging(app_name="restoguide", level=os.getenv("LOG_LEVEL", "INFO"))
logger = get_logger("app")

# --- Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ø¯Ø§Ø®Ù„ÙŠØ© (Ø¹Ø¨Ø± Ø¬Ø³ÙˆØ± utils/*) ---
from utils.content_fetch import fetch_and_extract, configure_http_cache, clear_http_cache
from utils.openai_client import get_client, chat_complete_cached
from utils.llm_cache import LLMCacher
from utils.quality_checks import quality_report
from utils.llm_reviewer import llm_review, llm_fix
from utils.places_provider import search_places  # ÙˆØ§Ø¬Ù‡Ø© Google Places Ø§Ù„Ù…ÙˆØ­Ù‘Ø¯Ø©
from utils.wp_client import WPClient  # Ø¹Ù…ÙŠÙ„ ÙˆÙˆØ±Ø¯Ø¨Ø±ÙŠØ³ Ù„Ù„Ù†Ø´Ø±

# ============================= Ù…Ø³Ø§Ø¹Ø¯Ø§Øª Ø¹Ø§Ù…Ø© =============================

def safe_rerun():
    if getattr(st, "rerun", None):
        st.rerun()
    else:
        st.experimental_rerun()

def _has_api_key() -> bool:
    # Ø®ØµÙŠØµÙ‹Ø§ Ù„Ù…ÙØªØ§Ø­ OpenAI
    try:
        if hasattr(st, "secrets") and st.secrets.get("OPENAI_API_KEY"):
            return True
    except Exception:
        pass
    return bool(os.getenv("OPENAI_API_KEY"))

def slugify(name: str) -> str:
    s = ''.join(c for c in unicodedata.normalize('NFKD', name or "") if not unicodedata.combining(c))
    import re as _re
    s = _re.sub(r'\W+', '-', s).strip('-').lower()
    return s or "item"

PROMPTS_DIR = Path("prompts")

def _read_file_any(path: Path) -> Optional[str]:
    try:
        return path.read_text(encoding="utf-8")
    except Exception:
        return None

def read_prompt(name: str) -> str:
    # ÙŠØ­Ø§ÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹ Ù…Ø¬Ù„Ø¯ prompts/ Ø«Ù… Ø§Ù„Ø¬Ø°Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ
    txt = _read_file_any(PROMPTS_DIR / name)
    if txt is None:
        txt = _read_file_any(Path(name))
    if txt is None:
        return f"<!-- missing prompt: {name} -->"
    return txt

# ======= Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„Ù†ØµÙˆØµ =======
BASE_TMPL = read_prompt("base.md")
POLISH_TMPL = read_prompt("polish.md")
FAQ_TMPL = read_prompt("faq.md")
METH_TMPL = read_prompt("methodology.md")
CRITERIA_MAP = {
    "Ø¨ÙŠØªØ²Ø§": read_prompt("criteria_pizza.md"),
    "Ù…Ù†Ø¯ÙŠ": read_prompt("criteria_mandy.md"),
    "Ø¨Ø±Ø¬Ø±": read_prompt("criteria_burger.md"),
    "ÙƒØ§ÙÙŠÙ‡Ø§Øª": read_prompt("criteria_cafes.md"),
}
GENERAL_CRITERIA = read_prompt("criteria_general.md")

# ============================= ÙˆØ§Ø¬Ù‡Ø© =============================
st.set_page_config(page_title="Ù…ÙˆÙ„Ø¯ Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø·Ø§Ø¹Ù… â€” Places + E-E-A-T", page_icon="ğŸ½ï¸", layout="wide")
st.title("ğŸ½ï¸ Ù…ÙˆÙ„Ø¯ Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø·Ø§Ø¹Ù… â€” Google Places + E-E-A-T + FAQ + ÙˆÙˆØ±Ø¯Ø¨Ø±ÙŠØ³")

# --- Sidebar: Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ø±ÙŠØ±ÙŠØ© ---
st.sidebar.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©")

tone = st.sidebar.selectbox(
    "Ù†ØºÙ…Ø© Ø§Ù„Ø£Ø³Ù„ÙˆØ¨",
    ["Ù†Ø§Ù‚Ø¯ ÙˆØ¯ÙˆØ¯", "Ù†Ø§Ù‚Ø¯ ØµØ§Ø±Ù…", "Ø¯Ù„ÙŠÙ„ ØªØ­Ø±ÙŠØ±ÙŠ Ù…Ø­Ø§ÙŠØ¯", "Ù†Ø§Ù‚Ø¯ ØµØ§Ø±Ù… | Ù…Ø±Ø§Ø¬Ø¹Ø§Øª Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±", "Ù†Ø§Ù‚Ø¯ ØµØ§Ø±Ù… | ØªØ¬Ø±Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø© + Ù…Ø±Ø§Ø¬Ø¹Ø§Øª"],
    index=0,
    key="tone_select",
)

primary_model = st.sidebar.selectbox("Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ", ["gpt-4.1", "gpt-4o", "gpt-4o-mini"], index=1, key="model_primary")
fallback_model = st.sidebar.selectbox("Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ø¯ÙŠÙ„ (Fallback)", ["gpt-4o", "gpt-4o-mini", "gpt-4.1"], index=2, key="model_fallback")
approx_len = st.sidebar.slider("Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ (ÙƒÙ„Ù…Ø§Øª)", 600, 1800, 1100, step=100, key="approx_len")
include_faq = st.sidebar.checkbox("Ø¥Ø¶Ø§ÙØ© FAQ", value=True, key="include_faq")
include_methodology = st.sidebar.checkbox("Ø¥Ø¶Ø§ÙØ© Ù…Ù†Ù‡Ø¬ÙŠØ© Ø§Ù„ØªØ­Ø±ÙŠØ±", value=True, key="include_methodology")
add_human_touch = st.sidebar.checkbox("Ø·Ø¨Ù‚Ø© Ù„Ù…Ø³Ø§Øª Ø¨Ø´Ø±ÙŠØ© (Polish)", value=True, key="do_polish")

# --- Sidebar: ÙƒÙ„Ù…Ø§Øª Ø¥Ù„Ø²Ø§Ù…ÙŠØ© ---
mandatory_terms_raw = st.sidebar.text_area(
    "ÙƒÙ„Ù…Ø§Øª/Ø¹Ø¨Ø§Ø±Ø§Øª Ø¥Ù„Ø²Ø§Ù…ÙŠØ© (Ø³Ø·Ø± Ù„ÙƒÙ„ Ø¹Ù†ØµØ±)",
    value="Ù…Ø·Ø§Ø¹Ù… Ø¹Ø§Ø¦Ù„ÙŠØ©\nØ¬Ù„Ø³Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ©\nÙ…ÙˆØ§Ù‚Ù Ø³ÙŠØ§Ø±Ø§Øª",
    height=100,
    key="mandatory_terms",
)
def _normalize_lines(s: str) -> List[str]:
    return [ln.strip() for ln in (s or "").splitlines() if ln.strip()]

mandatory_terms = _normalize_lines(mandatory_terms_raw)

# --- Sidebar: ÙƒØ§Ø´ HTTP Ù„Ø¬Ù„Ø¨ Ø§Ù„ØµÙØ­Ø§Øª (requests-cache Ø¹Ø¨Ø± content_fetch) ---
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ—„ï¸ ÙƒØ§Ø´ HTTP (Ù„Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ)")
http_cache_enabled = st.sidebar.checkbox("ØªÙØ¹ÙŠÙ„ ÙƒØ§Ø´ HTTP", value=True, key="http_cache_enabled")
http_cache_hours = st.sidebar.slider("Ù…Ø¯Ø© Ø§Ù„ÙƒØ§Ø´ (Ø³Ø§Ø¹Ø§Øª)", 1, 72, 24, key="http_cache_hours")
if st.sidebar.button("ğŸ§¹ Ù…Ø³Ø­ ÙƒØ§Ø´ HTTP", key="clear_http_cache"):
    try:
        ok = clear_http_cache()
        st.sidebar.success("ØªÙ… Ù…Ø³Ø­ ÙƒØ§Ø´ HTTP." if ok else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§Ø´.")
    except Exception as e:
        st.sidebar.warning(f"ØªØ¹Ø°Ù‘Ø± Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´: {e}")

try:
    configure_http_cache(enabled=http_cache_enabled, hours=http_cache_hours)
except Exception as e:
    st.sidebar.warning(f"ØªØ¹Ø°Ù‘Ø± ØªÙ‡ÙŠØ¦Ø© ÙƒØ§Ø´ HTTP: {e}")

# --- Sidebar: ÙƒØ§Ø´ LLM ---
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ§  ÙƒØ§Ø´ LLM")
llm_cache_enabled = st.sidebar.checkbox("ØªÙØ¹ÙŠÙ„ ÙƒØ§Ø´ LLM", value=True, key="llm_cache_enabled")
llm_cache_hours = st.sidebar.slider("Ù…Ø¯Ø© ÙƒØ§Ø´ LLM (Ø³Ø§Ø¹Ø§Øª)", 1, 72, 24, key="llm_cache_hours")
if "llm_cacher" not in st.session_state:
    st.session_state["llm_cacher"] = LLMCacher(ttl_hours=llm_cache_hours, enabled=llm_cache_enabled)
else:
    st.session_state["llm_cacher"].configure(enabled=llm_cache_enabled, ttl_hours=llm_cache_hours)

if st.sidebar.button("ğŸ§¹ Ù…Ø³Ø­ ÙƒØ§Ø´ LLM", key="clear_llm_cache"):
    ok = st.session_state["llm_cacher"].clear()
    st.sidebar.success("ØªÙ… Ù…Ø³Ø­ ÙƒØ§Ø´ LLM." if ok else "ØªØ¹Ø°Ù‘Ø± Ø§Ù„Ù…Ø³Ø­.")

# --- Sidebar: Ø±ÙˆØ§Ø¨Ø· Ø¯Ø§Ø®Ù„ÙŠØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) ---
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ”— Ø±ÙˆØ§Ø¨Ø· Ø¯Ø§Ø®Ù„ÙŠØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")
internal_catalog = st.sidebar.text_area(
    "Ø£Ø¯Ø®Ù„ Ø¹Ù†Ø§ÙˆÙŠÙ†/Ø³Ù„Ø§Ú¯Ø² (Ø³Ø·Ø± Ù„ÙƒÙ„ Ø¹Ù†ØµØ±)",
    value="Ø£ÙØ¶Ù„ Ù…Ø·Ø§Ø¹Ù… Ø§Ù„Ø±ÙŠØ§Ø¶\nØ£ÙØ¶Ù„ Ù…Ø·Ø§Ø¹Ù… Ø¥ÙØ·Ø§Ø± ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶\nØ£ÙØ¶Ù„ Ù…Ø·Ø§Ø¹Ù… Ø¨Ø±Ø¬Ø± ÙÙŠ Ø¬Ø¯Ø©",
    height=90,
    key="internal_links_catalog",
)

# ============================= Ø£Ø¯ÙˆØ§Øª Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ù…Ø§ÙƒÙ† =============================

def _dedupe_places(rows: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Ø¥Ø²Ø§Ù„Ø© ØªÙƒØ±Ø§Ø±Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ (Ø§Ù„Ù‡Ø§ØªÙ/Ø§Ù„Ù…ÙˆÙ‚Ø¹/Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ­Ù‘Ø¯)."""
    seen = set()
    out = []
    for r in rows:
        k = (r.get("phone") or "").strip() or (r.get("website") or "").strip() or slugify(r.get("name") or "")
        if k and k not in seen:
            seen.add(k)
            out.append(r)
    return out

def _score_place(row: Dict[str, Any], keyword: str) -> float:
    """ØªÙ‚ÙŠÙŠÙ… Ø°ÙƒÙŠ: rating Ã— log(reviews) + Boost Ù„Ù„ØªØ·Ø§Ø¨Ù‚ + open_now boost."""
    rating = float(row.get("rating") or 0.0)
    reviews = max(1, int(row.get("reviews_count") or 1))
    base = rating * math.log(reviews + 1.0)
    name = (row.get("name") or "").lower()
    kw = (keyword or "").lower().strip()
    boost_kw = 0.6 if kw and kw in name else 0.0
    boost_open = 0.3 if row.get("open_now") else 0.0
    return round(base + boost_kw + boost_open, 4)

def _extract_thursday_hours(row: Dict[str, Any]) -> str:
    """
    ÙŠÙØ¬Ø¨ÙØ± Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø¹Ù…Ù„ Ù„ØªÙƒÙˆÙ† Ù„ÙŠÙˆÙ… Ø§Ù„Ø®Ù…ÙŠØ³ ÙÙ‚Ø· (Ø­Ø³Ø¨ Ø·Ù„Ø¨Ùƒ).
    ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ù‚Ù„ÙŠÙ†: 'hours_map' (dict) Ø£Ùˆ 'hours_today' (fallback).
    """
    hours_map = row.get("hours_map") or {}
    thu = None
    # Ù…ÙØ§ØªÙŠØ­ Ù…Ø­ØªÙ…Ù„Ø© Ø¹Ø±Ø¨ÙŠØ©/Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
    for key in ["Ø§Ù„Ø®Ù…ÙŠØ³", "Thursday", "Thu"]:
        if key in hours_map and hours_map[key]:
            thu = hours_map[key]
            break
    if not thu:
        # Ø£Ø­ÙŠØ§Ù†Ù‹Ø§ ÙŠØ£ØªÙŠ hours_today ÙƒÙ€ "Ø§Ù„Ø®Ù…ÙŠØ³: 12:00â€“2:00"
        ht = (row.get("hours_today") or "").strip()
        if "Ø§Ù„Ø®Ù…ÙŠØ³" in ht or "Thursday" in ht or "Thu" in ht:
            thu = ht.split(":", 1)[-1].strip()
    return thu or "â€”"

def _build_references(rows: List[Dict[str, Any]]) -> List[str]:
    """
    ÙŠØµÙ†Ø¹ Ù‚Ø§Ø¦Ù…Ø© Ù…Ø±Ø§Ø¬Ø¹ [^n] Ù„ÙƒÙ„ Ø¹Ù†ØµØ±: ÙŠØ¯Ù…Ø¬ google_url + website (Ø¥Ù† ÙˆØ¬Ø¯).
    """
    refs = []
    for r in rows:
        google_url = r.get("google_url") or r.get("gmaps_url") or "â€”"
        site = r.get("website") or "â€”"
        if site and site != "â€”":
            refs.append(f"{r.get('name','?')}: Google Maps {google_url} â€” Website {site}")
        else:
            refs.append(f"{r.get('name','?')}: Google Maps {google_url}")
    return refs

def _criteria_normalize(raw):
    """Ø­ÙˆÙ‘Ù„ Ø£ÙŠ Ù†Ø§ØªØ¬ (list/tuple/dict/str JSON) Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù†ØµÙˆØµ Ù†Ø¸ÙŠÙØ© Ø¨Ù„Ø§ undefined."""
    if raw is None:
        return []
    if isinstance(raw, str):
        s = raw.strip()
        if s and s[0] in "[{":
            try:
                raw = json.loads(s)
            except Exception:
                lines = [ln.strip(" -â€¢\t").strip() for ln in s.splitlines() if ln.strip()]
                return [ln for ln in lines if ln and ln.lower() != "undefined"]
        else:
            lines = [ln.strip(" -â€¢\t").strip() for ln in s.splitlines() if ln.strip()]
            return [ln for ln in lines if ln and ln.lower() != "undefined"]
    if isinstance(raw, dict):
        for k in ("criteria", "bullets", "items", "list"):
            if k in raw:
                raw = raw[k]
                break
        else:
            vals = list(raw.values())
            raw = vals if all(isinstance(v, str) for v in vals) else list(raw.keys())
    if isinstance(raw, (list, tuple)):
        out = []
        for x in raw:
            if isinstance(x, str):
                t = x.strip().strip(",").strip('"').strip("'")
            elif isinstance(x, dict) and "text" in x:
                t = str(x["text"]).strip()
            else:
                t = str(x).strip()
            if t and t.lower() != "undefined":
                out.append(t)
        return out
    return [str(raw)]

def _format_criteria_md(items):
    items = _criteria_normalize(items)
    return "\n".join(f"- {c}" for c in items) or "- â€”"

# ============================= Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª =============================

tab_places, tab_article, tab_qc, tab_publish = st.tabs(
    ["ğŸ›°ï¸ Ù…ØµØ§Ø¯Ø± Google", "âœï¸ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§Ù„", "ğŸ§ª ÙØ­ÙˆØµØ§Øª Ø§Ù„Ø¬ÙˆØ¯Ø©", "ğŸ“ Ù†Ø´Ø± ÙˆÙˆØ±Ø¯Ø¨Ø±ÙŠØ³"]
)

# -------------------- ØªØ¨ÙˆÙŠØ¨ 1: Ø¬Ù„Ø¨ ÙˆØªÙ†Ù‚ÙŠØ© Google Places --------------------
with tab_places:
    st.subheader("ğŸ›°ï¸ Google Places (Ø¬Ù„Ø¨ & ØªÙ†Ù‚ÙŠØ©)")
    col1, col2, col3, col4 = st.columns([2, 1.2, 1, 1])
    with col1:
        gp_keyword = st.text_input("Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©", "Ù…Ø·Ø§Ø¹Ù… Ø¨Ø±Ø¬Ø± ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶", key="gp_kw")
    with col2:
        gp_city = st.text_input("Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©", "Ø§Ù„Ø±ÙŠØ§Ø¶", key="gp_city")
    with col3:
        gp_min_reviews = st.number_input("Ø­Ø¯ Ø£Ø¯Ù†Ù‰ Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø§Øª", min_value=0, max_value=5000, value=50, step=10, key="gp_min_reviews")
    with col4:
        btn_fetch = st.button("ğŸ“¥ Ø¬Ù„Ø¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", use_container_width=False, key="btn_gp_fetch")

    if btn_fetch:
        corr = set_correlation_id()
        try:
            with with_context(correlation_id=corr, stage="places.fetch"):
                logger.info("places.fetch.start", extra={"correlation_id": corr})
                rows = search_places(keyword=gp_keyword, city=gp_city, min_reviews=int(gp_min_reviews))
                # ØªÙ†Ù‚ÙŠØ© ÙˆØªÙ‚ÙŠÙŠÙ…
                rows = _dedupe_places(rows)
                for r in rows:
                    r["score"] = _score_place(r, gp_keyword)
                    r["hours_thursday"] = _extract_thursday_hours(r)
                rows.sort(key=lambda x: x["score"], reverse=True)
                # Ø±Ø§ÙŠØ© ØªØ­Ø°ÙŠØ± Ø¥Ù† Ø§Ù„Ø¹Ø¯Ø¯ Ù‚Ù„ÙŠÙ„
                if len(rows) < 6:
                    st.warning("âš ï¸ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ù‚Ù„ Ù…Ù† 6 Ø¹Ù†Ø§ØµØ± â€” Ù‚Ø¯ ØªÙƒÙˆÙ† Ø¶Ø¹ÙŠÙØ© Ù„Ù„Ù†Ø´Ø±.")
                # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                st.dataframe(rows, width='stretch')
                # ØªØ®Ø²ÙŠÙ† ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©
                st.session_state["places_results"] = rows
                logger.info("places.fetch.done", extra={"correlation_id": corr, "count": len(rows)})
        except Exception as e:
            log_exception(logger, "places.fetch.error")
            st.error(f"ØªØ¹Ø°Ù‘Ø± Ø§Ù„Ø¬Ù„Ø¨: {e}")

    st.markdown("---")
    btn_accept = st.button("âœ”ï¸ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©", key="btn_accept_places", use_container_width=False)
    if btn_accept:
        rows = st.session_state.get("places_results") or []
        if not rows:
            st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù„Ø§Ø¹ØªÙ…Ø§Ø¯Ù‡Ø§. Ù‚Ù… Ø¨Ø§Ù„Ø¬Ù„Ø¨ Ø£ÙˆÙ„Ù‹Ø§.")
        else:
            # Snapshot Ù†Ø¸ÙŠÙ + Ù…Ø±Ø§Ø¬Ø¹
            snap = []
            for r in rows:
                snap.append({
                    "name": r.get("name"),
                    "address": r.get("address"),
                    "phone": r.get("phone"),
                    "website": r.get("website"),
                    "google_url": r.get("google_url") or r.get("gmaps_url"),
                    "rating": r.get("rating"),
                    "reviews_count": r.get("reviews_count"),
                    "price_band": r.get("price_band"),
                    "open_now": r.get("open_now"),
                    # Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø®Ù…ÙŠØ³ Ø«Ø§Ø¨ØªØ© Ø­Ø³Ø¨ Ø·Ù„Ø¨Ùƒ
                    "hours_thursday": r.get("hours_thursday") or _extract_thursday_hours(r),
                })
            refs = _build_references(snap)
            st.session_state["places_snapshot"] = snap
            st.session_state["places_references"] = refs
            st.success("ØªÙ… Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙƒÙ…ØµØ¯Ø± Ø­Ù‚Ø§Ø¦Ù‚ Ù„Ù„Ù…Ù‚Ø§Ù„.")
            logger.info("places.accepted")

# -------------------- ØªØ¨ÙˆÙŠØ¨ 2: ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§Ù„ --------------------
with tab_article:
    st.subheader("âœï¸ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§Ù„ (Ø³Ø±Ø¯ + FAQ + Ù…Ø±Ø§Ø¬Ø¹)")

    colA, colB = st.columns([2, 1])
    with colA:
        article_title = st.text_input("Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‚Ø§Ù„", "Ø£ÙØ¶Ù„ Ù…Ø·Ø§Ø¹Ù… Ø¨Ø±Ø¬Ø± ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶", key="article_title")
        article_keyword = st.text_input("Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", "Ù…Ø·Ø§Ø¹Ù… Ø¨Ø±Ø¬Ø± ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶", key="article_kw")

        # Ø§Ø®ØªÙŠØ§Ø± ÙØ¦Ø©/Ù…Ø¹Ø§ÙŠÙŠØ± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        built_in_labels = list(CRITERIA_MAP.keys())
        content_scope = st.selectbox(
            "Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ø­ØªÙˆÙ‰",
            ["ÙØ¦Ø© Ù…Ø­Ø¯Ø¯Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…ÙƒØ§Ù†", "Ø´Ø§Ù…Ù„ Ø¨Ù„Ø§ ÙØ¦Ø©", "Ù‡Ø¬ÙŠÙ† (ØªÙ‚Ø³ÙŠÙ… Ø¯Ø§Ø®Ù„ÙŠ)"],
            index=0,
            key="content_scope",
        )

        if content_scope == "ÙØ¦Ø© Ù…Ø­Ø¯Ø¯Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…ÙƒØ§Ù†":
            category_choice = st.selectbox("Ø§Ù„ÙØ¦Ø©", built_in_labels + ["ÙØ¦Ø© Ù…Ø®ØµÙ‘ØµØ©â€¦"], index=2, key="category_select")
            if category_choice == "ÙØ¦Ø© Ù…Ø®ØµÙ‘ØµØ©â€¦":
                category = st.text_input("Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…Ø®ØµÙ‘ØµØ©", "Ù…Ø·Ø§Ø¹Ù… Ø¨Ø±Ø¬Ø±", key="custom_category_name")
                criteria_block = st.text_area(
                    "Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)",
                    value="- Ø¬ÙˆØ¯Ø© Ø§Ù„Ù„Ø­Ù… ÙˆØ§Ù„Ø®Ø¨Ø²\n- Ø«Ø¨Ø§Øª Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø·Ù‡ÙŠ\n- Ø§Ù„Ø³Ø¹Ø± Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ù‚ÙŠÙ…Ø©\n- Ø³Ø±Ø¹Ø© Ø§Ù„Ø®Ø¯Ù…Ø© ÙˆØ§Ù„Ù†Ø¸Ø§ÙØ©",
                    height=120,
                    key="custom_criteria_text",
                )
            else:
                category = category_choice
                criteria_block = CRITERIA_MAP.get(category_choice, GENERAL_CRITERIA)
        else:
            category = "Ø¹Ø§Ù…"
            criteria_block = GENERAL_CRITERIA

        # Ø¯Ù…Ø¬ Snapshot
        snap = st.session_state.get("places_snapshot") or []
        refs = st.session_state.get("places_references") or []

        st.caption("Ø³ÙŠØªÙ… ØªØ¶Ù…ÙŠÙ† Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ù…Ø§ÙƒÙ† Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø© ÙƒØ­Ù‚Ø§Ø¦Ù‚ Ù…Ø¶ØºÙˆØ·Ø© + Ø¥Ø­Ø§Ù„Ø§Øª [^n].")
        st.write(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø©: **{len(snap)}**")

        # ØªØ­Ø¶ÙŠØ± Ù‚Ø§Ø¦Ù…Ø© Ø£Ø³Ù…Ø§Ø¡ (Ø¥Ù† Ø£Ø±Ø¯Øª Ø¥Ø¸Ù‡Ø§Ø±Ù‡Ø§ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…)
        if snap:
            names_preview = ", ".join([s["name"] for s in snap[:8]]) + ("â€¦" if len(snap) > 8 else "")
            st.info(f"Ø£Ø¨Ø±Ø² Ø§Ù„Ø£Ù…Ø§ÙƒÙ†: {names_preview}")

        # Ù…Ù„Ø§Ø­Ø¸Ø§Øª ÙŠØ¯ÙˆÙŠØ© Ø§Ø®ØªÙŠØ§Ø±ÙŠØ©
        manual_notes = st.text_area("Ù…Ù„Ø§Ø­Ø¸Ø§Øª ÙŠØ¯ÙˆÙŠØ© ØªÙØ¯Ù…Ø¬ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø³Ø±Ø¯ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", height=120, key="article_notes")

    with colB:
        st.subheader("Ù‚Ø§Ø¦Ù…Ø© ØªØ¯Ù‚ÙŠÙ‚ Ø¨Ø´Ø±ÙŠØ©")
        checks = {
            "sensory": st.checkbox("ÙˆØµÙ Ø­Ø³ÙŠ (Ø±Ø§Ø¦Ø­Ø©/Ù‚ÙˆØ§Ù…/Ø­Ø±Ø§Ø±Ø©) Ù„Ù…Ø·Ø¹Ù… ÙˆØ§Ø­Ø¯+", key="chk_sensory"),
            "personal": st.checkbox("Ù…Ù„Ø§Ø­Ø¸Ø©/ØªÙØ¶ÙŠÙ„ Ø´Ø®ØµÙŠ", key="chk_personal"),
            "compare": st.checkbox("Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø²ÙŠØ§Ø±Ø© Ø³Ø§Ø¨Ù‚Ø©/Ù…Ø·Ø¹Ù… Ù…Ø´Ø§Ø¨Ù‡", key="chk_compare"),
            "critique": st.checkbox("Ù†Ù‚Ø·Ø© Ù†Ù‚Ø¯ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹Ø©", key="chk_critique"),
            "vary": st.checkbox("ØªÙ†ÙˆÙŠØ¹ Ø£Ø·ÙˆØ§Ù„ Ø§Ù„ÙÙ‚Ø±Ø§Øª", key="chk_vary"),
        }

        include_jsonld = st.checkbox("ØªØ¶Ù…ÙŠÙ† JSON-LD (Article + FAQ)", value=True, key="include_jsonld")

    # Ø²Ø± ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§Ù„
    if st.button("ğŸš€ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§Ù„", key="btn_generate_article", use_container_width=False):
        if not _has_api_key():
            st.error("Ù„Ø§ ÙŠÙˆØ¬Ø¯ OPENAI_API_KEY.")
            st.stop()

        if not snap:
            st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚Ø§Ø¦Ù…Ø© Ø£Ù…Ø§ÙƒÙ† Ù…Ø¹ØªÙ…Ø¯Ø©. Ø§Ù†ØªÙ‚Ù„ Ù„ØªØ¨ÙˆÙŠØ¨ 'Ù…ØµØ§Ø¯Ø± Google' ÙˆØ§Ø¹ØªÙ…Ø¯ Ù‚Ø§Ø¦Ù…Ø© Ø£ÙˆÙ„Ù‹Ø§.")
            st.stop()

        client = get_client()
        cacher = st.session_state.get("llm_cacher")

        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù†Ø¨Ø±Ø©
        if tone == "Ù†Ø§Ù‚Ø¯ ØµØ§Ø±Ù… | Ù…Ø±Ø§Ø¬Ø¹Ø§Øª Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±":
            tone_instructions = ("Ø§ÙƒØªØ¨ ÙƒÙ†Ø§Ù‚Ø¯ ØµØ§Ø±Ù… ÙŠØ¹ØªÙ…Ø¯ Ø£Ø³Ø§Ø³Ù‹Ø§ Ø¹Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø§Øª Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø© Ø¹Ù„Ù†Ù‹Ø§. "
                                 "Ø±ÙƒÙ‘Ø² Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© ÙˆØ§Ø°ÙƒØ± Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù…Ù†Ù‡Ø¬ÙŠØ©. Ù„Ø§ ØªØ¯Ù‘Ø¹Ù Ø²ÙŠØ§Ø±Ø© Ø´Ø®ØµÙŠØ©. Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø£Ø±Ù‚Ø§Ù…Ù‹Ø§ Ù…Ø¨Ø§Ù„ØºÙ‹Ø§ ÙÙŠÙ‡Ø§.")
            tone_selection_line = "Ø§Ø¹ØªÙ…Ø¯Ù†Ø§ Ù…Ø±Ø§Ø¬Ø¹Ø§Øª Ù…ÙˆØ«ÙˆÙ‚Ø© Ù…Ù†Ø´ÙˆØ±Ø© Ø¹Ù„Ù†Ù‹Ø§ Ø­ØªÙ‰ {last_updated}."
            system_tone = "Ø£Ø³Ù„ÙˆØ¨ Ù†Ø§Ù‚Ø¯ ØµØ§Ø±Ù… Ù…Ø±ØªÙƒØ² Ø¹Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø§Øª Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±"
        elif tone == "Ù†Ø§Ù‚Ø¯ ØµØ§Ø±Ù… | ØªØ¬Ø±Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø© + Ù…Ø±Ø§Ø¬Ø¹Ø§Øª":
            tone_instructions = ("Ø§ÙƒØªØ¨ ÙƒÙ†Ø§Ù‚Ø¯ ØµØ§Ø±Ù… ÙŠÙ…Ø²Ø¬ Ø®Ø¨Ø±Ø© Ù…ÙŠØ¯Ø§Ù†ÙŠØ© Ù…Ø¹ Ù…Ø±Ø§Ø¬Ø¹Ø§Øª Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±. "
                                 "Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø­ÙƒÙ… Ù…Ù† Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© Ø£ÙˆÙ„Ù‹Ø§ Ø«Ù… Ù‚Ø§Ø±Ù†Ù‡ Ø¨Ø§Ù†Ø·Ø¨Ø§Ø¹Ø§Øª Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±. Ø£Ø¯Ø±Ø¬ **Ù†Ù‚Ø·Ø© Ù„Ù„ØªØ­Ø³ÙŠÙ†** Ù„ÙƒÙ„ Ù…Ø·Ø¹Ù….")
            tone_selection_line = "Ù…Ø²Ø¬Ù†Ø§ Ø¨ÙŠÙ† Ø²ÙŠØ§Ø±Ø§Øª Ù…ÙŠØ¯Ø§Ù†ÙŠØ© ÙˆØªØ¬Ø§Ø±Ø¨ ÙØ¹Ù„ÙŠØ© ÙˆÙ…Ø±Ø§Ø¬Ø¹Ø§Øª Ø¹Ø§Ù…Ø© Ø­ØªÙ‰ {last_updated}."
            system_tone = "Ø£Ø³Ù„ÙˆØ¨ Ù†Ø§Ù‚Ø¯ ØµØ§Ø±Ù… ÙŠÙ…Ø²Ø¬ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ø¹ Ù…Ø±Ø§Ø¬Ø¹Ø§Øª Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±"
        else:
            tone_instructions = "Ø§ÙƒØªØ¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…ØªÙˆØ§Ø²Ù† ÙŠØ±Ø§Ø¹ÙŠ Ø§Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„ÙˆØ¶ÙˆØ­ Ø¯ÙˆÙ† Ù…Ø¨Ø§Ù„ØºØ©."
            tone_selection_line = "Ø§Ø¹ØªÙ…Ø¯Ù†Ø§ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© ÙˆÙ…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙˆØ«ÙˆÙ‚Ø© Ù…ØªØ§Ø­Ø©ØŒ Ù…Ø¹ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¯ÙˆØ±ÙŠØ©."
            system_tone = tone

        last_updated = datetime.now().strftime("%B %Y")

        # ØªØ¬Ù‡ÙŠØ² Ø­Ù‚Ø§Ø¦Ù‚ Ù…Ø¶ØºÙˆØ·Ø© + Ø¥Ø­Ø§Ù„Ø§Øª
        # Ù†Ø³ØªØ®Ø¯Ù… Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø®Ù…ÙŠØ³ Ø§Ù„Ø«Ø§Ø¨ØªØ© ÙƒÙ…Ø§ Ø·Ù„Ø¨ØªØŒ ÙˆÙ†Ø¨Ù‚ÙŠ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ù…ÙˆØ¬Ø²Ø©
        facts_lines = []
        for idx, s in enumerate(snap, start=1):
            facts_lines.append(
                f"- {s['name']} â€” Ø³Ø¹Ø±: {s.get('price_band','â€”')} â€” Ø³Ø§Ø¹Ø§Øª Ø§Ù„Ø®Ù…ÙŠØ³: {s.get('hours_thursday','â€”')} â€” Ù‡Ø§ØªÙ: {s.get('phone','â€”')} [^{idx}]"
            )
        facts_block = "\n".join(facts_lines)
        refs_block = "\n".join([f"[^{i+1}]: {r}" for i, r in enumerate(refs)])

        faq_block = FAQ_TMPL if include_faq else "â€”"
        methodology_block = (METH_TMPL.format(last_updated=last_updated) if include_methodology else "â€”")

        # Ø¯Ù…Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ© ÙƒÙ†ØµÙŠØ­Ø© Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ø·Ø¨ÙŠØ¹ÙŠÙ‹Ø§ (Ø¨Ø¯ÙˆÙ† Ø­Ø´Ùˆ)
        mandatory_hint = ""
        if mandatory_terms:
            mandatory_hint = "Ø£Ø¯Ø±Ø¬ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ ØºÙŠØ± Ù‚Ø³Ø±ÙŠ Ø¶Ù…Ù† Ø§Ù„Ø³Ø±Ø¯ Ù…ØªÙ‰ ÙƒØ§Ù† Ù…Ù„Ø§Ø¦Ù…Ù‹Ø§: " + ", ".join(f"â€œ{t}â€" for t in mandatory_terms) + "."

        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ (ÙŠØ¹ØªÙ…Ø¯ base.md Ù„Ø¯ÙŠÙƒ)
        base_prompt = BASE_TMPL.format(
            title=article_title,
            keyword=article_keyword,
            content_scope=content_scope,
            category=category,
            restaurants_list=", ".join([s["name"] for s in snap]),
            criteria_block=_format_criteria_md(criteria_block),
            faq_block=faq_block,
            methodology_block=methodology_block,
            tone_label=tone,
            place_context="â€”",
            protip_hint="â€”",
            scope_instructions="Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ø³Ø±Ø¯ Ø§Ù„Ø¥Ù†Ø³Ø§Ù†ÙŠ Ù…Ø¹ Ø¥Ø­Ø§Ù„Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹ [^n].",
            tone_instructions=tone_instructions + " " + mandatory_hint,
            tone_selection_line=tone_selection_line.replace("{last_updated}", last_updated),
        )

        # Ù†Ø¶ÙŠÙ Ø­Ù‚Ø§Ø¦Ù‚ Ø§Ù„Ø£Ù…Ø§ÙƒÙ† ÙˆØ§Ù„Ù…Ø±Ø§Ø¬Ø¹ ÙƒÙ…Ù„Ø­Ù‚ Ù„Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª
        base_messages = [
            {"role": "system", "content": f"Ø§ÙƒØªØ¨ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰. {system_tone}. Ø·ÙˆÙ„ ØªÙ‚Ø±ÙŠØ¨ÙŠ {approx_len} ÙƒÙ„Ù…Ø©."},
            {"role": "user", "content":
                base_prompt
                + "\n\n---\n\n"
                + "## Ø­Ù‚Ø§Ø¦Ù‚ Ù…Ø¶ØºÙˆØ·Ø© Ø¹Ù† Ø§Ù„Ø£Ù…Ø§ÙƒÙ† (Ù„Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø³Ø±Ø¯ Ø¨Ø¥Ø­Ø§Ù„Ø§Øª [^n]):\n"
                + facts_block
                + "\n\n## Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ (Ø¶Ø¹ [^n] Ø¹Ù†Ø¯ Ø§Ù„Ø§Ø³ØªØ´Ù‡Ø§Ø¯):\n"
                + refs_block
            },
        ]

        try:
            article_md = chat_complete_cached(
                client, base_messages,
                max_tokens=2200, temperature=0.7,
                model=primary_model, fallback_model=fallback_model,
                cacher=cacher, cache_extra={"purpose": "article_base", "kw": article_keyword}
            )
        except Exception as e:
            log_exception(logger, "llm.article.error")
            st.error(f"ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§Ù„: {e}")
            st.stop()

        # Ø·Ø¨Ù‚Ø© Polish (Ø§Ø®ØªÙŠØ§Ø±ÙŠ + Ø¯Ù…Ø¬ Ù…Ù„Ø§Ø­Ø¸Ø§Øª)
        apply_polish = add_human_touch or any(checks.values())
        if apply_polish or (manual_notes.strip()):
            polish_prompt = POLISH_TMPL.format(article=article_md, user_notes=manual_notes)
            polish_messages = [
                {"role": "system", "content": "Ø£Ù†Øª Ù…Ø­Ø±Ø± Ø¹Ø±Ø¨ÙŠ Ù…Ø­ØªØ±ÙØŒ ØªØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ ÙˆØªØ¶ÙŠÙ Ù„Ù…Ø³Ø§Øª Ø¨Ø´Ø±ÙŠØ© Ø¨Ø¯ÙˆÙ† Ù…Ø¨Ø§Ù„ØºØ© ÙˆØ¨Ù„Ø§ Ø­Ø´Ùˆ."},
                {"role": "user", "content": polish_prompt},
            ]
            try:
                article_md = chat_complete_cached(
                    client, polish_messages,
                    max_tokens=2400, temperature=0.8,
                    model=primary_model, fallback_model=fallback_model,
                    cacher=cacher, cache_extra={"purpose": "article_polish"}
                )
            except Exception as e:
                st.warning(f"ØªØ¹Ø°Ù‘Ø±Øª Ø·Ø¨Ù‚Ø© Ø§Ù„Ù„Ù…Ø³Ø§Øª Ø§Ù„Ø¨Ø´Ø±ÙŠØ©: {e}")

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ© + Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¯Ù…Ø§Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¥Ù† Ù„Ø²Ù…
        missing_terms = [t for t in mandatory_terms if t not in article_md]
        if missing_terms:
            st.warning("Ø¨Ø¹Ø¶ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ© Ù„Ù… ØªØ¸Ù‡Ø± ÙÙŠ Ø§Ù„Ù†Øµ ÙˆØ³ÙŠØªÙ… Ø¥Ø¯Ù…Ø§Ø¬Ù‡Ø§ Ø¨Ù„Ø·Ù.")
            try:
                fix_messages = [
                    {"role": "system", "content": "Ø£Ù†Øª Ù…Ø­Ø±Ø± Ø¹Ø±Ø¨ÙŠ ØªÙØ¯Ø±Ø¬ Ø¹Ø¨Ø§Ø±Ø§Øª Ù…Ø­Ø¯Ø¯Ø© Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ ÙˆØ¯Ù‚ÙŠÙ‚ ÙÙŠ Ø§Ù„Ù†Øµ Ø¨Ø¯ÙˆÙ† Ø¥ÙØ³Ø§Ø¯ Ø§Ù„Ø³Ø±Ø¯ Ø£Ùˆ Ø¥Ø¶Ø§ÙØ© Ø­Ø´Ùˆ."},
                    {"role": "user", "content": f"Ø£Ø¯Ø±Ø¬ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Øµ Ø£Ø¯Ù†Ø§Ù‡ Ø­ÙŠØ« ÙŠÙƒÙˆÙ† Ù…Ù„Ø§Ø¦Ù…Ù‹Ø§ ÙÙ‚Ø·: {', '.join(missing_terms)}.\n\nØ§Ù„Ù†Øµ:\n{article_md}"}
                ]
                article_md = chat_complete_cached(
                    client, fix_messages,
                    max_tokens=2000, temperature=0.4,
                    model=primary_model, fallback_model=fallback_model,
                    cacher=cacher, cache_extra={"purpose": "article_terms_fix", "missing": missing_terms}
                )
            except Exception:
                pass

        # Ø¹Ù†ÙˆØ§Ù† ÙˆÙˆØµÙ SEO
        try:
            meta_out = chat_complete_cached(
                client,
                [
                    {"role":"system","content":"Ø£Ù†Øª Ù…Ø®ØªØµ SEO Ø¹Ø±Ø¨ÙŠ."},
                    {"role":"user","content": f"ØµÙØº Ø¹Ù†ÙˆØ§Ù† SEO (â‰¤ 60) ÙˆÙˆØµÙ Ù…ÙŠØªØ§ (â‰¤ 155) Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ù…Ù‚Ø§Ù„ Ø¨Ø¹Ù†ÙˆØ§Ù† \"{article_title}\". Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {article_keyword}.\nTITLE: ...\nDESCRIPTION: ..."}
                ],
                max_tokens=200, temperature=0.6,
                model=primary_model, fallback_model=fallback_model,
                cacher=cacher, cache_extra={"purpose": "article_meta", "title": article_title}
            )
        except Exception:
            meta_out = f"TITLE: {article_title}\nDESCRIPTION: Ø¯Ù„ÙŠÙ„ Ø¹Ù…Ù„ÙŠ Ø¹Ù† {article_keyword}."

        # Ø±ÙˆØ§Ø¨Ø· Ø¯Ø§Ø®Ù„ÙŠØ© Ù…Ù‚ØªØ±Ø­Ø©
        links_catalog = [s.strip() for s in internal_catalog.splitlines() if s.strip()]
        try:
            links_out = chat_complete_cached(
                client,
                [
                    {"role":"system","content":"Ø£Ù†Øª Ù…Ø­Ø±Ø± Ø¹Ø±Ø¨ÙŠ ÙŠÙ‚ØªØ±Ø­ Ø±ÙˆØ§Ø¨Ø· Ø¯Ø§Ø®Ù„ÙŠØ© Ø·Ø¨ÙŠØ¹ÙŠØ©."},
                    {"role":"user","content": f"Ø§Ù‚ØªØ±Ø­ 3 Ø±ÙˆØ§Ø¨Ø· Ø¯Ø§Ø®Ù„ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø© Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¥Ù† Ø£Ù…ÙƒÙ†:\n{links_catalog}\nØ§Ù„Ø¹Ù†ÙˆØ§Ù†: {article_title}\nØ§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: {article_keyword}\nÙ…Ù‚ØªØ·Ù:\n{article_md[:800]}\n- Ø±Ø§Ø¨Ø· Ø¯Ø§Ø®Ù„ÙŠ Ù…Ù‚ØªØ±Ø­: <Ø§Ù„Ù†Øµ>"}
                ],
                max_tokens=240, temperature=0.5,
                model=primary_model, fallback_model=fallback_model,
                cacher=cacher, cache_extra={"purpose": "article_links"}
            )
        except Exception:
            links_out = "- Ø±Ø§Ø¨Ø· Ø¯Ø§Ø®Ù„ÙŠ Ù…Ù‚ØªØ±Ø­: Ø£ÙØ¶Ù„ Ù…Ø·Ø§Ø¹Ù… Ø§Ù„Ø±ÙŠØ§Ø¶\n- Ø±Ø§Ø¨Ø· Ø¯Ø§Ø®Ù„ÙŠ Ù…Ù‚ØªØ±Ø­: Ø¯Ù„ÙŠÙ„ Ù…Ø·Ø§Ø¹Ù… Ø§Ù„Ø¹Ø§Ø¦Ù„Ø§Øª ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶\n- Ø±Ø§Ø¨Ø· Ø¯Ø§Ø®Ù„ÙŠ Ù…Ù‚ØªØ±Ø­: Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ù†Ù…Ø§Ø·"

        # Ø¥Ø®Ø±Ø§Ø¬
        st.subheader("ğŸ“„ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ù†Ø§ØªØ¬")
        st.markdown(article_md)
        st.session_state['last_article_md'] = article_md

        st.subheader("ğŸ” Meta (SEO)")
        st.code(meta_out, language="text")

        st.subheader("ğŸ”— Ø±ÙˆØ§Ø¨Ø· Ø¯Ø§Ø®Ù„ÙŠØ© Ù…Ù‚ØªØ±Ø­Ø©")
        st.markdown(links_out)

        # Ø­ÙØ¸ JSON
        out_json = {
            "title": article_title,
            "keyword": article_keyword,
            "category": category,
            "content_scope": content_scope,
            "places_snapshot": snap,
            "references": refs,
            "last_updated": last_updated,
            "tone": tone,
            "models": {"primary": primary_model, "fallback": fallback_model},
            "include_faq": include_faq,
            "include_methodology": include_methodology,
            "article_markdown": article_md,
            "meta": meta_out,
            "internal_links": links_out,
        }
        st.session_state['last_json'] = json.dumps(out_json, ensure_ascii=False, indent=2)

        # ØªÙ†Ø²ÙŠÙ„Ø§Øª
        cold1, cold2, cold3 = st.columns(3)
        with cold1:
            st.download_button('ğŸ’¾ ØªÙ†Ø²ÙŠÙ„ Markdown', data=article_md, file_name='article.md', mime='text/markdown', key="dl_md")
        with cold2:
            from utils.exporters import to_docx, to_json
            st.download_button('ğŸ“ ØªÙ†Ø²ÙŠÙ„ DOCX', data=to_docx(article_md), file_name='article.docx',
                               mime='application/vnd.openxmlformats-officedocument.wordprocessingml.document', key="dl_docx")
        with cold3:
            st.download_button('ğŸ§© ØªÙ†Ø²ÙŠÙ„ JSON', data=st.session_state['last_json'], file_name='article.json', mime='application/json', key="dl_json")

# -------------------- ØªØ¨ÙˆÙŠØ¨ 3: ÙØ­ÙˆØµØ§Øª Ø§Ù„Ø¬ÙˆØ¯Ø© --------------------
with tab_qc:
    st.subheader("ğŸ§ª ÙØ­Øµ Ø¨Ø´Ø±ÙŠØ© ÙˆØ¬ÙˆØ¯Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰")
    qc_text = st.text_area("Ø§Ù„ØµÙ‚ Ù†Øµ Ø§Ù„Ù…Ù‚Ø§Ù„ Ù‡Ù†Ø§", st.session_state.get("last_article_md",""), height=300, key="qc_text")
    col_q1, col_q2, col_q3 = st.columns(3)
    with col_q1:
        do_fluff = st.checkbox("ÙƒØ´Ù Ø§Ù„Ø­Ø´Ùˆ ÙˆØ§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø§Ù„Ø¨ÙŠØ©", value=True, key="qc_fluff")
    with col_q2:
        do_eeat = st.checkbox("Ù…Ø¤Ø´Ø±Ø§Øª E-E-A-T", value=True, key="qc_eeat")
    with col_q3:
        do_llm_review = st.checkbox("ØªØ´Ø®ÙŠØµ Ù…ÙØ±Ø´Ø¯ (LLM)", value=True, key="qc_llm")

    if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹", key="btn_qc_fast"):
        if not qc_text.strip():
            st.warning("Ø§Ù„ØµÙ‚ Ø§Ù„Ù†Øµ Ø£ÙˆÙ„Ù‹Ø§.")
        else:
            rep = quality_report(qc_text)
            st.session_state["qc_report"] = rep
            st.markdown("### Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„Ø¯Ø±Ø¬Ø§Øª")
            colA, colB, colC = st.columns(3)
            with colA: st.metric("Human-style Score", rep["human_style_score"])
            with colB: st.metric("Sensory Ratio", rep["sensory_ratio"])
            with colC: st.metric("Fluff Density", rep["fluff_density"])
            st.markdown("#### ØªÙ†ÙˆÙ‘Ø¹ Ø§Ù„Ø¬Ù…Ù„"); st.json(rep["sentence_variety"])
            if do_eeat:
                st.markdown("#### E-E-A-T"); st.json({"presence": rep["eeat"], "score": rep["eeat_score"]})
                st.markdown("#### Information Gain"); st.json({"score": rep["info_gain_score"]})
            if do_fluff:
                st.markdown("#### Ø¹Ø¨Ø§Ø±Ø§Øª Ù‚Ø§Ù„Ø¨ÙŠØ© Ù…Ø±ØµÙˆØ¯Ø©")
                boiler = rep.get("boilerplate_flags") or []
                if boiler:
                    for f in boiler:
                        pattern = f.get("pattern", "?")
                        excerpt = f.get("excerpt", "")
                        st.write(f"- **Ù†Ù…Ø·:** `{pattern}` â€” Ù…Ù‚ØªØ·Ù: â€¦{excerpt}â€¦")
                else:
                    st.caption("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¹Ø¨Ø§Ø±Ø§Øª Ù‚Ø§Ù„Ø¨ÙŠØ© Ø¸Ø§Ù‡Ø±Ø©.")
                repeats = rep.get("repeated_phrases") or []
                if repeats:
                    st.markdown("#### Ø¹Ø¨Ø§Ø±Ø§Øª Ù…ØªÙƒØ±Ø±Ø© Ø¨Ø´ÙƒÙ„ Ø²Ø§Ø¦Ø¯")
                    for g, c in repeats:
                        st.write(f"- `{g}` Ã— {c}")
            st.success("Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹.")
            st.session_state["qc_text"] = qc_text

    if do_llm_review and st.button("ğŸ§  ØªØ´Ø®ÙŠØµ Ù…ÙØ±Ø´Ø¯ (LLM)", key="btn_qc_llm"):
        if not qc_text.strip():
            st.warning("Ø§Ù„ØµÙ‚ Ø§Ù„Ù†Øµ Ø£ÙˆÙ„Ù‹Ø§.")
        elif not _has_api_key():
            st.error("Ù„Ø§ ÙŠÙˆØ¬Ø¯ OPENAI_API_KEY.")
        else:
            client = get_client()
            out = llm_review(client, primary_model, fallback_model, qc_text)
            st.markdown("### ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…ÙØ±Ø§Ø¬Ø¹"); st.markdown(out)
            st.session_state["qc_review_md"] = out

    st.markdown("---")
    st.markdown("#### Ø¥ØµÙ„Ø§Ø­ Ø°ÙƒÙŠ Ù„Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…Ø¹Ù„Ù‘Ù…Ø©")
    flagged_block = st.text_area("Ø£Ù„ØµÙ‚ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ø¶Ø¹ÙŠÙØ© (Ø³Ø·Ø± Ù„ÙƒÙ„ Ù…Ù‚Ø·Ø¹)", height=140, key="qc_flagged")
    if st.button("âœï¸ Ø£Ø¹ÙØ¯ Ø§Ù„ØµÙŠØ§ØºØ© Ù„Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙÙ‚Ø·", key="btn_qc_fix"):
        if not flagged_block.strip():
            st.warning("Ø£Ø¯Ø®Ù„ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø£ÙˆÙ„Ù‹Ø§.")
        elif not qc_text.strip():
            st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ø£Ø³Ø§Ø³ Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ÙƒØªØ§Ø¨Ø©.")
        elif not _has_api_key():
            st.error("Ù„Ø§ ÙŠÙˆØ¬Ø¯ OPENAI_API_KEY.")
        else:
            client = get_client()
            new_text = llm_fix(client, primary_model, fallback_model, qc_text, flagged_block.splitlines())
            st.markdown("### Ø§Ù„Ù†Øµ Ø¨Ø¹Ø¯ Ø§Ù„Ø¥ØµÙ„Ø§Ø­"); st.markdown(new_text)
            st.session_state["last_article_md"] = new_text
            st.success("ØªÙ… Ø§Ù„Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…ÙˆØ¶Ø¹ÙŠ.")

# -------------------- ØªØ¨ÙˆÙŠØ¨ 4: Ù†Ø´Ø± ÙˆÙˆØ±Ø¯Ø¨Ø±ÙŠØ³ --------------------
with tab_publish:
    st.subheader("ğŸ“ Ø§Ù„Ù†Ø´Ø± Ø¹Ù„Ù‰ ÙˆÙˆØ±Ø¯Ø¨Ø±ÙŠØ³ (Draft)")
    st.caption("ÙŠÙÙ†ØµØ­ Ø¨Ø§Ù„Ù†Ø´Ø± ÙƒÙ…Ø³ÙˆØ¯Ø© Ø«Ù… Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ØªØ­Ø±ÙŠØ±ÙŠØ© Ù‚Ø¨Ù„ Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ.")

    # Ù†Ù‚Ø±Ø£ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù† secrets ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ (ÙƒÙ…Ø§ Ø§ØªÙÙ‚Ù†Ø§)
    wp_url = st.secrets.get("WP_BASE_URL", "") if hasattr(st, "secrets") else os.getenv("WP_BASE_URL", "")
    wp_user = st.secrets.get("WP_USERNAME", "") if hasattr(st, "secrets") else os.getenv("WP_USERNAME", "")
    wp_app_pass = st.secrets.get("WP_APP_PASSWORD", "") if hasattr(st, "secrets") else os.getenv("WP_APP_PASSWORD", "")

    colp1, colp2 = st.columns([2, 1])
    with colp1:
        post_title = st.text_input("Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØªØ¯ÙˆÙŠÙ†Ø©", st.session_state.get("article_title", "Ø£ÙØ¶Ù„ Ù…Ø·Ø§Ø¹Ù… Ø¨Ø±Ø¬Ø± ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶"), key="wp_post_title")
        post_slug = st.text_input("Slug (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", slugify(post_title), key="wp_post_slug")
    with colp2:
        post_status = st.selectbox("Ø§Ù„Ø­Ø§Ù„Ø©", ["draft", "publish", "pending"], index=0, key="wp_post_status")

    city_tag = st.text_input("ÙˆØ³Ù… Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©", "Ø§Ù„Ø±ÙŠØ§Ø¶", key="wp_city_tag")
    category_name = st.text_input("ØªØµÙ†ÙŠÙ Ø±Ø¦ÙŠØ³ÙŠ", "Ù…Ø·Ø§Ø¹Ù…", key="wp_category")

    dataset_meta_key = st.text_input("Ù…ÙØªØ§Ø­ Ù…ÙŠØªØ§ Ù„Ø­ÙØ¸ Dataset", "places_json", key="wp_meta_key")

    btn_publish = st.button("ğŸ“¤ Ø£Ù†Ø´Ø± ÙƒÙ€ Draft", key="btn_publish_wp", use_container_width=False)

    if btn_publish:
        article_md = st.session_state.get("last_article_md", "")
        if not article_md:
            st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­ØªÙˆÙ‰ Ø¬Ø§Ù‡Ø² Ù„Ù„Ù†Ø´Ø±. ÙˆÙ„Ù‘Ø¯ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø£ÙˆÙ„Ù‹Ø§.")
        elif not (wp_url and wp_user and wp_app_pass):
            st.error("Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙˆØ±Ø¯Ø¨Ø±ÙŠØ³ ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø© ÙÙŠ secrets/env.")
        else:
            # ØªØ­Ø¶ÙŠØ± JSON-LD (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            jsonld_blocks = []
            if st.session_state.get("include_jsonld", True):
                # Article
                jsonld_blocks.append({
                    "@context": "https://schema.org",
                    "@type": "Article",
                    "headline": post_title,
                    "datePublished": datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ"),
                    "inLanguage": "ar",
                })
                # FAQPage (Ø¥Ù† ÙƒØ§Ù† FAQ Ø¶Ù…Ù† Ø§Ù„Ù…Ù‚Ø§Ù„)
                if include_faq:
                    jsonld_blocks.append({
                        "@context": "https://schema.org",
                        "@type": "FAQPage",
                        "mainEntity": []
                    })
            jsonld_html = ""
            if jsonld_blocks:
                jsonld_html = "<script type='application/ld+json'>\n" + json.dumps(jsonld_blocks, ensure_ascii=False, indent=2) + "\n</script>"

            # Ù…Ø­ØªÙˆÙ‰ HTML Ù…Ø¨Ø³Ù‘Ø· (ÙŠÙ…ÙƒÙ† Ù„Ø§Ø­Ù‚Ù‹Ø§ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ­ÙˆÙŠÙ„)
            html_content = f"<div class='article-body'>\n{article_md}\n</div>\n{jsonld_html}"

            try:
                client = WPClient(
                    base_url=wp_url,
                    username=wp_user,
                    app_password=wp_app_pass
                )
                result = client.post_or_update(
                    title=post_title,
                    content_html=html_content,
                    slug=post_slug,
                    status=post_status,
                    tags=[city_tag] if city_tag else [],
                    categories=[category_name] if category_name else [],
                    meta={dataset_meta_key: st.session_state.get("last_json", "{}")},
                    find_existing_by="slug"  # ÙŠØ¬Ù†Ø¨ Ø§Ù„Ø§Ø²Ø¯ÙˆØ§Ø¬ÙŠØ©
                )
                st.success("ØªÙ… Ø¥Ù†Ø´Ø§Ø¡/ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø³ÙˆØ¯Ø© Ø¨Ù†Ø¬Ø§Ø­.")
                if result and result.get("link"):
                    st.markdown(f"ğŸ”— Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø³ÙˆØ¯Ø©: {result['link']}")
            except Exception as e:
                log_exception(logger, "wp.publish.error")
                st.error(f"ÙØ´Ù„ Ø§Ù„Ù†Ø´Ø±: {e}")
